{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# https://python.langchain.com/docs/integrations/document_loaders/pypdfloader/#add-a-custom-pages_delimiter-to-identify-where-are-ends-of-pages-in-single-mode\n",
    "def pdf_loader(pdf_path: str):\n",
    "    return PyPDFLoader(\n",
    "        pdf_path,\n",
    "        mode=\"single\",\n",
    "        pages_delimiter=\"\\n-------END OF PAGE-------\\n\",\n",
    "    )\n",
    "\n",
    "dream_dictionary_docs = pdf_loader(\"assets/data/The_Dreamers_Dictionary.pdf\").load()\n",
    "jung_archetypes_docs = pdf_loader(\"assets/data/The_Archetypes_of_the_Collective_Unconscious_C.Jung.pdf\").load()\n",
    "jung_interpretations_docs = pdf_loader(\"assets/data/Symbols_and_the_Interpretation_of_Dreams_by_Carl_Jung.pdf\").load()\n",
    "personality_types_docs = pdf_loader(\"assets/data/Understanding Personality - The 12 Jungian Archetypes.pdf\").load()\n",
    "freud_interpretations_docs = pdf_loader(\"assets/data/The Interpretation of Dreams - Sigmund Freud (1900).pdf\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,                # chunk size (characters)\n",
    "    chunk_overlap=200,              # chunk overlap (characters)\n",
    "    add_start_index=True,           # track index in original document\n",
    ")\n",
    "dream_dictionary_splits = text_splitter.split_documents(dream_dictionary_docs)\n",
    "jung_archetypes_splits = text_splitter.split_documents(jung_archetypes_docs)\n",
    "jung_interpretations_splits = text_splitter.split_documents(jung_interpretations_docs)\n",
    "personality_types_splits = text_splitter.split_documents(personality_types_docs)\n",
    "freud_interpretations_splits = text_splitter.split_documents(freud_interpretations_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings  # local\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "    model_kwargs={\"device\": \"cuda\"}, # use 'cpu' in case you don't have a gpu\n",
    ")\n",
    "\n",
    "# Create In-Memory Vector Stores\n",
    "dream_dictionary_store = InMemoryVectorStore(embeddings)\n",
    "jung_archetypes_store = InMemoryVectorStore(embeddings)\n",
    "jung_interpretations_store = InMemoryVectorStore(embeddings)\n",
    "personality_types_store = InMemoryVectorStore(embeddings)\n",
    "freud_interpretations_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "attempting embed...\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nattempting embed...\\n\")\n",
    "dream_dictionary_store.add_documents(documents=dream_dictionary_splits)\n",
    "jung_archetypes_store.add_documents(documents=jung_archetypes_splits)\n",
    "jung_interpretations_store.add_documents(documents=jung_interpretations_splits)\n",
    "personality_types_store.add_documents(documents=personality_types_splits)\n",
    "freud_interpretations_store.add_documents(documents=freud_interpretations_splits)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done storing\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\n",
    "    \"assets/pickles/dream_dictionary_store.dat\", mode=\"wb\"\n",
    ") as f_dream_dictionary_store, open(\n",
    "    \"assets/pickles/jung_archetypes_store.dat\", mode=\"wb\"\n",
    ") as f_jung_archetypes_store, open(\n",
    "    \"assets/pickles/jung_interpretations_store.dat\", mode=\"wb\"\n",
    ") as f_jung_interpretations_store, open(\n",
    "    \"assets/pickles/personality_types_store.dat\", mode=\"wb\"\n",
    ") as f_personality_types_store, open(\n",
    "    \"assets/pickles/freud_interpretations_store.dat\", mode=\"wb\"\n",
    ") as f_freud_interpretations_store:\n",
    "    pickle.dump(freud_interpretations_store, f_freud_interpretations_store)\n",
    "    pickle.dump(dream_dictionary_store, f_dream_dictionary_store)\n",
    "    pickle.dump(jung_archetypes_store, f_jung_archetypes_store)\n",
    "    pickle.dump(jung_interpretations_store, f_jung_interpretations_store)\n",
    "    pickle.dump(personality_types_store, f_personality_types_store)\n",
    "    print(\"done storing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnsupportedOperation",
     "evalue": "read",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnsupportedOperation\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpickle\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33massets/pickles/dream_dictionary_store.dat\u001b[39m\u001b[33m\"\u001b[39m, mode=\u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m f_dream_dictionary_store, \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33massets/pickles/freud_interpretations_store.dat\u001b[39m\u001b[33m\"\u001b[39m, mode=\u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     13\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m f_freud_interpretations_store:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     freud_interpretations_store = \u001b[43mpickle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_freud_interpretations_store\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     dream_dictionary_store = pickle.load(f_dream_dictionary_store)\n\u001b[32m     16\u001b[39m     jung_archetypes_store = pickle.load(f_jung_archetypes_store)\n",
      "\u001b[31mUnsupportedOperation\u001b[39m: read"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\n",
    "    \"assets/pickles/dream_dictionary_store.dat\", mode=\"rb\"\n",
    ") as f_dream_dictionary_store, open(\n",
    "    \"assets/pickles/jung_archetypes_store.dat\", mode=\"rb\"\n",
    ") as f_jung_archetypes_store, open(\n",
    "    \"assets/pickles/jung_interpretations_store.dat\", mode=\"rb\"\n",
    ") as f_jung_interpretations_store, open(\n",
    "    \"assets/pickles/personality_types_store.dat\", mode=\"rb\"\n",
    ") as f_personality_types_store, open(\n",
    "    \"assets/pickles/freud_interpretations_store.dat\", mode=\"rb\"\n",
    ") as f_freud_interpretations_store:\n",
    "    freud_interpretations_store = pickle.load(f_freud_interpretations_store)\n",
    "    dream_dictionary_store = pickle.load(f_dream_dictionary_store)\n",
    "    jung_archetypes_store = pickle.load(f_jung_archetypes_store)\n",
    "    jung_interpretations_store = pickle.load(f_jung_interpretations_store)\n",
    "    personality_types_store = pickle.load(f_personality_types_store)\n",
    "    print(\"done loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_ollama.chat_models.ChatOllama'>\n",
      "{\"archetype\":\"Everyman\"} {\"dream\":0.0,\"question\":1.0,\"statement\":0.0,\"truth\":0.0,\"greeting\":0.0}\n"
     ]
    }
   ],
   "source": [
    "from typing import (\n",
    "    Optional,\n",
    "    List,\n",
    "    Tuple,\n",
    ")  # https://docs.python.org/3/library/typing.html\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_ollama import ChatOllama\n",
    "from pydantic._internal._model_construction import ModelMetaclass\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2:3b\",\n",
    "    temperature=0,\n",
    "    # other params...\n",
    ")\n",
    "print(type(llm))\n",
    "\n",
    "\n",
    "dream_text = \"I had a dream where I was in a crowd of pigeons and I couldn't move forward, but I was getting late for my dance competition. Suddenly, I was on my mom's shoulders and the pigeons turned into humans.\"\n",
    "# dream_text = \"I'm not sure if this was a dream of a hallucination, but I could see myself falling into the abyss as I was thinking of my next meeting. The very next thing I knew, I woke up sudeenly on my toilet seat, when I clearly remember being home.\"\n",
    "\n",
    "\n",
    "class dream_classification(BaseModel):\n",
    "    \"\"\"Classify the kind of prompt. Probabilities range from 0 to 1.\"\"\"\n",
    "\n",
    "    # archetype: str = Field(description=\"Jungian archetype.\")\n",
    "    dream: float = Field(description=\"probability of it being a dream. Values can range from 0 to 1\")\n",
    "    question: float = Field(description=\"probability of it being a question being asked. Values can range from 0 to 1\")\n",
    "    statement: float = Field(description=\"probability of it being a general statement. Values can range from 0 to 1\")\n",
    "    truth: float = Field(description=\"probability of it being a well known truth. Values can range from 0 to 1\")\n",
    "    greeting: float = Field(description=\"probability of it being a greeting. Values can range from 0 to 1\")\n",
    "\n",
    "\n",
    "class archetype_classification(BaseModel):\n",
    "    \"\"\"Dream Analysis.\"\"\"\n",
    "\n",
    "    # archetype: str = Field(description=\"Jungian archetype.\")\n",
    "    archetype: str = Field(\n",
    "        description=\"Archetype based on context and dream. It should be one of Ruler, Creator/Artist, Sage, Innocent, Explorer, Rebel, Hero, Wizard, Jester, Everyman, Lover, Caregiver\"\n",
    "    )\n",
    "\n",
    "\n",
    "# print(run(dream_text, prompt, llm, archetype_classification))\n",
    "dream_dictionary_results = dream_dictionary_store.similarity_search(dream_text)\n",
    "jung_archetypes_results = jung_archetypes_store.similarity_search(dream_text)\n",
    "jung_interpretations_results = jung_interpretations_store.similarity_search(dream_text)\n",
    "personality_types_results = personality_types_store.similarity_search(dream_text)\n",
    "\n",
    "\n",
    "def parse(result):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in result)\n",
    "\n",
    "\n",
    "dream_dictionary_context = parse(dream_dictionary_results)\n",
    "jung_archetypes_context = parse(jung_archetypes_results)\n",
    "jung_interpretations_context = parse(jung_interpretations_results)\n",
    "personality_types_context = parse(personality_types_results)\n",
    "\n",
    "\n",
    "prompt = f\"Dream: {dream_text}\\n\\nJungian context: {personality_types_results}\"\n",
    "answer = llm.with_structured_output(archetype_classification).invoke(prompt)\n",
    "\n",
    "print(\n",
    "    answer.model_dump_json(),\n",
    "    llm.with_structured_output(dream_classification)\n",
    "    .invoke(f\"Dream: {dream_text}\")\n",
    "    .model_dump_json(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "> testing out huggingface embeddinngs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# https://python.langchain.com/docs/integrations/chat/huggingface/#huggingfacepipeline\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    temperature=0,\n",
    ")\n",
    "llm = ChatHuggingFace(llm=llm)\n",
    "\n",
    "dream_text = \"I dreamt of kissing my girlfriend\"\n",
    "\n",
    "dream_dictionary_results = dream_dictionary_store.similarity_search(dream_text)\n",
    "jung_archetypes_results = jung_archetypes_store.similarity_search(dream_text)\n",
    "jung_interpretations_results = jung_interpretations_store.similarity_search(dream_text)\n",
    "\n",
    "def parse(result):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in result)\n",
    "\n",
    "dream_dictionary_context = parse(dream_dictionary_results)\n",
    "jung_archetypes_context = parse(jung_archetypes_results)\n",
    "jung_interpretations_context = parse(jung_interpretations_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def validate_user(archetype: str, interpretation: str) -> bool:\n",
    "    \"\"\"Interpret the user's dream using the given context.\n",
    "\n",
    "    Args:\n",
    "        archetype (str): Jungian archetype.\n",
    "        interpretation (str): Interpretation of the dream based on the Jungian archetype.\n",
    "    \"\"\"\n",
    "    return True\n",
    "\n",
    "\n",
    "llm = llm.bind_tools([validate_user])\n",
    "\n",
    "result = llm.invoke(\n",
    "    f\"\"\"{dream_text}\\n\\nJungian archetype context: {jung_archetypes_context}\"\"\"\n",
    ")\n",
    "result.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pprint import pprint\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Interpret the user's dream using the given context. Give me the result in a json format only, with the keys: ['archetype', 'interpretation']\n",
    "\n",
    "    dream: {dream_text}\n",
    "    Jungian archetype context: {jung_archetypes_context}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "dream_text = \"I was kissing my wife\"\n",
    "\n",
    "chain = prompt | llm\n",
    "answer = chain.invoke({\"dream_text\": dream_text, \"jung_archetypes_context\": jung_interpretations_context})\n",
    "\n",
    "pprint(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
